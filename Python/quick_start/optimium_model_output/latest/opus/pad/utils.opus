module core
module core.List.List as ll
module common.utils as commonutils
module common.uniontensor as ut

type TemplateParameters = {input_type : rtType, input_dtype : rtType, input_shape : ll.List<i32>,
                           output_type : rtType, output_dtype : rtType, output_shape : ll.List<i32>,
                           framework : string, nchw : bool, pad : ll.List<ll.List<i32>>,
                           scales: ut.UnionTensor, zero_points: ut.UnionTensor}

type CodeGenParameters = {
    input_type : rtType,
    input_dtype : rtType,
    input_shape : ll.List<i32>,
    output_type : rtType,
    output_dtype : rtType,
    output_shape : ll.List<i32>,
    nchw : bool,
    pad : ll.List<ll.List<i32>>,
    range_index : ll.List,
    zerotns_str : string, 
    scales: ut.UnionTensor,
    zero_points: ut.UnionTensor
}

let get_range params =
    let rec impl index = 
        if(index >= (ll.len <| params->input_shape)){
            []
        } else{
            let currange = [ll.item <| 0i <| (ll.item <| index <| params->pad): (( ll.item <| index <| params->input_shape) + ll.item <| 0i <| (ll.item <| index <| params->pad)):1i]
            ll.concat <| currange <| (impl <| (index+1i))
        }
    impl <| 0i

let initCodeGen params =
    let range_index = get_range <| params
    let codeGenParameters = CodeGenParameters(params->input_type, params->input_dtype, params->input_shape,
                                params->output_type, params->output_dtype, params->output_shape,
                                params->nchw, params->pad, range_index, 
                                "zerotns", params->scales, params->zero_points)
    
    codeGenParameters

let get_pad_chunk_shape replace_index replace_val params =
    let rec impl index = 
        if (index  == (ll.len <| params->input_shape)){
            []
        } else{
            if (index == replace_index){
                ll.concat <| [replace_val] <| (impl <| (index+1i))
            } else if (index > replace_index){
                ll.concat <| [ll.item <| index <| params->output_shape] <| (impl <| (index+1i))
            } else{
                ll.concat <| [ll.item <| index <| params->input_shape] <| (impl <| (index+1i))
            }
        }
    impl <| 0i

let get_pad_chunk_outidx curpadidx paddim_outidx params =
    let rec impl index =
        if(index >= (ll.len <| params->input_shape)){
            []
        } else if(index < curpadidx){
            let pad_front = ll.item <| 0i <| (ll.item <| index <| params->pad)
            ll.concat <| [pad_front: (pad_front + (ll.item <| index <| params->input_shape)):1i] <| (impl <| (index+1i))
        } else if(index == curpadidx){
            ll.concat <| [paddim_outidx] <| (impl <| (index+1i))
        } else{
            ll.concat <| [0i : (ll.item <| index <| params->output_shape):1i] <| (impl <| (index+1i))
        }
    impl <| 0i

let setFillPadExpr params nextop =
    let rec setFillPadExpr_impl index =
        if(index >= (ll.len <| params->input_shape)){
            !{
                ${nextop}
            }
        } else{
            let pad_front = ll.item <| 0i <| (ll.item <| index <| params->pad)
            let pad_back    = ll.item <| 1i <| (ll.item <| index <| params->pad)
            if( (pad_front + pad_back) == 0i){
                // nothing to pad
                setFillPadExpr_impl <| (index + 1i)
            } else{
                let front_expr pad_front nextstepop = 
                    if(pad_front > 0){
                        let chunk_shape = get_pad_chunk_shape <| index <| pad_front <| params
                        let flatnum = commonutils.factorial <| chunk_shape
                        match params->zero_points with
                        | ut.EMPTY -> 
                            let v = if(params->input_dtype == rtType(f32)){
                                tensor((flatnum,), 0.0f32)
                            } else if (params->input_dtype == rtType(f16)){
                                tensor((flatnum,), 0.0f16)
                            } else{
                                except("Wrong datatype for input dtype in pad")
                            }
                            let outidx = get_pad_chunk_outidx <| index <| (0i:pad_front:1i) <| params
                            !{
                                let ${params->zerotns_str + toStr(index) + "_" + toStr(0)} = ${v}
                                &batchoutput[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${params->zerotns_str + toStr(index) + "_" + toStr(0)})
                                ${nextstepop}
                            }
                        | ut.TensorI32 tns ->
                            if(shapeOf(tns)[|0|] == 1i){
                                // tensor-wise
                                let v = tensor((flatnum,), tns[(0,)])
                                let outidx = get_pad_chunk_outidx <| index <| (0i:pad_front:1i) <| params
                                !{
                                    let ${params->zerotns_str + toStr(index) + "_" + toStr(0)} = ${v}
                                    &batchoutput[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${params->zerotns_str + toStr(index) + "_" + toStr(0)})
                                    ${nextstepop}
                                }
                            } else{
                                // channel-wise
                                except("Not implemented for channel-wise quantization")
                            }
                        | _ -> except("not supported type for zero points")
                    } else{
                        !{
                            ${nextstepop}
                        }
                    }
                let expr1 = front_expr <| pad_front
                let back_expr pad_back = 
                    if(pad_back > 0){
                        let chunk_shape = get_pad_chunk_shape <| index <| pad_back <| params
                        let flatnum = commonutils.factorial <| chunk_shape
                        match params->zero_points with
                        | ut.EMPTY ->
                            let v = if(params->input_dtype == rtType(f32)){
                                tensor((flatnum,), 0.0f32)
                            } else if (params->input_dtype == rtType(f16)){
                                tensor((flatnum,), 0.0f16)
                            } else{
                                except("Wrong datatype for input dtype in pad")
                            }
                            let outidx = get_pad_chunk_outidx <| index <| ((ll.item <| index <| (params->output_shape)-pad_back):(ll.item <| index <| params->output_shape):1i) <| params
                            !{
                                let ${params->zerotns_str + toStr(index) + "_" + toStr(1)} = ${v}
                                &batchoutput[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${params->zerotns_str + toStr(index) + "_" + toStr(1)})
                                ${setFillPadExpr_impl <| (index+1i)}
                            }
                        | ut.TensorI32 tns ->
                            if(shapeOf(tns)[|0|] == 1i){
                                // tensor-wise
                                let v = tensor((flatnum,), tns[(0,)])
                                let outidx = get_pad_chunk_outidx <| index <| ((ll.item <| index <| (params->output_shape)-pad_back):(ll.item <| index <| params->output_shape):1i) <| params
                                !{
                                    let ${params->zerotns_str + toStr(index) + "_" + toStr(1)} = ${v}
                                    &batchoutput[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${params->zerotns_str + toStr(index) + "_" + toStr(1)})
                                    ${setFillPadExpr_impl <| (index+1i)}
                                }
                            } else{
                                // channel-wise
                                except("Not implemented for channel-wise quantization")
                            }
                    } else{
                        !{
                            ${setFillPadExpr_impl <| (index+1i)}
                        }
                    }
                let expr2 = back_expr <| pad_back
                expr1 <| expr2
            }
        }
    setFillPadExpr_impl <| 0i

let storeInput params =
    !{
        batchoutput[${ll.toRtTuple<| params->range_index}] <- batchinput
    }

let setBatch  params nextop =
    !{
        let mut batchoutput = &outputs[|0i|]
        let batchinput = inputs[|0i|]
        let _ = ${nextop}
        0
    }

_end_