module core.List.List as ll
module common.uniontensor as ut
module common.params as params

template</attr_params: params.Attributes, optim_params: params.Optimization, layer_params: ll.List<params.Layerargs>,
    input_data: ll.List<ll.List<ut.UnionTensor>>, input_dtypes: ll.List<ll.List<rtType>>, input_shapes: ll.List<ll.List<i32>>, input_scales: ll.List<ll.List<ut.UnionTensor>>, input_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    output_dtypes: ll.List<ll.List<rtType>>, output_shapes: ll.List<ll.List<i32>>, output_scales: ll.List<ll.List<ut.UnionTensor>>, output_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    input_edges: ll.List<ll.List<tuple<i32, i32>>>, output_edges: ll.List<ll.List<tuple<i32, i32>>>, ismainops: ll.List<boolean>,
    input_t: rtType, input_rt_list : ll.List<rtType>,  output_t: rtType, output_rt_list : ll.List<rtType>/>
attr[Extern : attr_params->name, Optimization : { VectorSize : 512 }]
fun tanh(inputs: input_t, mut &outputs: output_t) -> i32 {
    ${
        let input_dtype = ll.item 0 (ll.item 0 input_dtypes)
        let input_shape = ll.item 0 (ll.item 0 input_shapes)
        let input_scales = ll.item 0 (ll.item 0 input_scales)
        let input_zero_points = ll.item 0 (ll.item 0 input_zero_points)
        let output_dtype = ll.item 0 (ll.item 0 output_dtypes)
        let output_shape = ll.item 0 (ll.item 0 output_shapes)
        let output_scales = ll.item 0 (ll.item 0 output_scales)
        let output_zero_points = ll.item 0 (ll.item 0 output_zero_points)

        let rec shape_size index shape data =
            if (index == (ll.len shape)) {
                data
            } else {
                shape_size (index+1) shape (data*(ll.item index shape))
            }

        let input_size = shape_size 0 input_shape 1
        let output_size = shape_size 0 output_shape 1

        let pack = ll.item 0 (optim_params->pack)
        let unroll = ll.item 0 (optim_params->unroll)

        let lastshape = ll.item (ll.len input_shape - 1) input_shape
        let _ = if (pack * unroll > lastshape) {
            except("pack * unroll(" + toStr(pack * unroll) + ") should be larger than one of the shape of last dimension of input(" + toStr(lastshape) + ")")
        } else {
            _end_
        }

        for (i from 0 to (ll.len output_shape)) {
            if (ll.item i output_shape == ll.item i input_shape) {
                _end_
            } else {
                except("output shape(" + toStr(output_shape) + ") is not compatible with expected shape(" + toStr(input_shape) + "}")
            }
        }

        let tiles =
            if (input_size % pack == 0) {
                [(0, input_size); (input_size, input_size)]
            } else {
                let end1 = input_size - (input_size % pack)
                [(0, end1); (end1, input_size)]
            }

        let isQuant = input_dtype == rtType(i8)

        let (start, end) = ll.item 0 tiles
        let (start2, end2) = ll.item 1 tiles

        let get_constants size =
            if (input_dtype == rtType(f32)) {
                !{
                    let neg_sat_cutoff = tensor((${size},), -1.5f32)
                    let pos_sat_cutoff = tensor((${size},), 1.5f32)

                    let c3 = tensor((${size},), -0.33330571651458740234375f32)
                    let c5 = tensor((${size},), 0.1330046951770782470703125f32)
                    let c7 = tensor((${size},), -0.05260427296161651611328125f32)
                    let c9 = tensor((${size},), 0.01905878819525241851806640625f32)
                    let c11 = tensor((${size},), -0.0055121383629739284515380859375f32)
                    let c13 = tensor((${size},), 0.00104447430931031703948974609375f32)
                    let c15 = tensor((${size},), -0.00009209793643094599246978759765625f32)

                    (&c3, &c5, &c7, &c9, &c11, &c13, &c15, &neg_sat_cutoff, &pos_sat_cutoff)
                }
            } else if (input_dtype == rtType(f16)) {
                !{
                    let neg_sat_cutoff = tensor((${size},), -1.5f16)
                    let pos_sat_cutoff = tensor((${size},), 1.5f16)

                    let c3 = tensor((${size},), -0.333333f16)
                    let c5 = tensor((${size},), 0.13330078125f16)
                    let c7 = tensor((${size},), -0.053192138671875f16)
                    let c9 = tensor((${size},), 0.0166015625f16)

                    (&c3, &c5, &c7, &c9, &neg_sat_cutoff, &pos_sat_cutoff)
                }
            } else {
                except("unsupported type: only f32, f16 supported")
            }

        let calculate_tanh =
            if (input_dtype == rtType(f32)) {
                !{
                    let x2 = __max(neg_sat_cutoff, x1)
                    let x3 = __min(pos_sat_cutoff, x2)
                    let x_square = x3 * x3

                    let mut p = c15 * x_square + c13
                    p <- p * x_square + c11
                    p <- p * x_square + c9
                    p <- p * x_square + c7
                    p <- p * x_square + c5
                    p <- p * x_square + c3

                    let xt = x3 * x_square
                    let result = p * xt + x3

                    &result
                }
            } else if (input_dtype == rtType(f16)) {
                !{
                    let x2 = __max(neg_sat_cutoff, x1)
                    let x3 = __min(pos_sat_cutoff, x2)
                    let x_square = x3 * x3

                    let mut p = c9 * x_square + c7
                    p <- p * x_square + c5
                    p <- p * x_square + c3

                    let xt = x3 * x_square
                    let result = p * xt + x3

                    &result
                }
            } else {
                except("unsupported type: only f32, f16 supported")
            }

        if (input_dtype == rtType(f32)) {
            let expr1 =
                !{
                    let (c3, c5, c7, c9, c11, c13, c15, neg_sat_cutoff, pos_sat_cutoff) = ${get_constants pack}

                    let x1 = input_reshaped[(idx0:idx0+${pack}:1i,)]

                    let xp = ${calculate_tanh}

                    output_reshaped[(idx0:idx0+${pack}:1i,)] <- xp
                }
            let expr2 =
                if (end2 - start2 > 0) {
                    !{
                        let (c3, c5, c7, c9, c11, c13, c15, neg_sat_cutoff, pos_sat_cutoff) = ${get_constants (end2 - start2)}

                        let x1 = input_reshaped[(${start2}:${end2}:1i,)] // f32

                        let xp = ${calculate_tanh}

                        output_reshaped[(${start2}:${end2}:1i,)]  <- xp
                        0
                    }
                } else {
                    !{0}
                }

            !{
                let mut batchoutput = &outputs[|0|]
                let batchinput = inputs[|0|]

                let input_reshaped = reshapeTo((${input_size},), &batchinput)
                let mut output_reshaped = reshapeTo((${output_size},), &batchoutput)

                for (idx0 from 0 to ${start2} step ${pack}) {
                    ${expr1}
                }

                ${expr2}
            }

        } else if (input_dtype == rtType(f16)) {
            let expr1 =
                !{
                    let (c3, c5, c7, c9, neg_sat_cutoff, pos_sat_cutoff) = ${get_constants pack}

                    let x1 = input_reshaped[(idx0:idx0+${pack}:1i,)]

                    let xp = ${calculate_tanh}

                    output_reshaped[(idx0:idx0+${pack}:1i,)] <- xp
                }
            let expr2 =
                if (end2 - start2 > 0) {
                    !{
                        let (c3, c5, c7, c9, neg_sat_cutoff, pos_sat_cutoff) = ${get_constants (end2 - start2)}

                        let x1 = input_reshaped[(${start2}:${end2}:1i,)]

                        let xp = ${calculate_tanh}

                        output_reshaped[(${start2}:${end2}:1i,)]  <- xp
                        0
                    }
                } else {
                    !{0}
                }

            !{
                let mut batchoutput = &outputs[|0|]
                let batchinput = inputs[|0|]

                let input_reshaped = reshapeTo((${input_size},), &batchinput)
                let mut output_reshaped = reshapeTo((${output_size},), &batchoutput)

                for (idx0 from 0 to ${start2} step ${pack}) {
                    ${expr1}
                }

                ${expr2}
            }

       } else {
            except("unsupported type: only f32, f16 supported")
        }
    }
}
