module core.List.List as ll
module common.uniontensor as ut
module micro.utils as mu
// let (isMain, passScale, setVars, loopOps, microOps, storeOps) = getMicroLayerImpl 

let isMain = false

let passScale input_scales output_scales = 
    let input_scale = ll.item 0 input_scales
    let output_scale = ll.item 0 output_scales

    if(ut.isEmpty input_scale){
        ([1.f], 32, true)
    } else{
        let si = ut.toCtTensorF32 input_scale
        let so = ut.toCtTensorF32 output_scale

        ([si / so], 16, true)
    }

let setVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale = 
    let alpha = ll.item 1 input_data
    let alpha_shape = ll.item 1 input_shapes
    let alpha_zero_points = ll.item 1 input_zero_points
    let input1_shape = ll.item 0 input_shapes
    let input1_dim = ll.len (ll.item 0 input_shapes)

    let rec shape_size index shape data =
        if(index == (ll.len shape)){
            data
        }
        else{
            shape_size (index+1) shape (data*(ll.item index shape))
        }

    let alpha_size = shape_size 0 alpha_shape 1

    let rec broadcast_shape_f32 input alpha a b ttensor index = 
        if(index == ll.len input){
            let length = shape_size 0 input1_shape 1
            ut.TensorF32(reshapeTo((length,),ttensor))
        }else{
            let axis_size = ll.item index input
            if(ll.item index input == ll.item index alpha){
                broadcast_shape_f32 input alpha (a/axis_size) (b*axis_size) ttensor (index+1)
            } else {
                let mut ret_tensor = tensor((a*b*axis_size,), 0.f32)
                for (i from 0 to (a*b) step a){
                    for (j from 0 to axis_size step 1){
                        ret_tensor[((i*axis_size + j*a):(i*axis_size + (j+1)*a):1,)] <- (ttensor[(i:(i+a):1,)])
                        _end_
                    }
                    _end_
                }
                broadcast_shape_f32 input alpha (a) (b*axis_size) ret_tensor (index+1)
            }
        }

    let rec broadcast_shape_f16 input alpha a b ttensor index = 
        if(index == ll.len input){
            let length = shape_size 0 input1_shape 1
            ut.TensorF16(reshapeTo((length,),ttensor))
        }else{
            let axis_size = ll.item index input
            if(ll.item index input == ll.item index alpha){
                broadcast_shape_f16 input alpha (a/axis_size) (b*axis_size) ttensor (index+1)
            } else {
                let mut ret_tensor = tensor((a*b*axis_size,), 0.f16)
                for (i from 0 to (a*b) step a){
                    for (j from 0 to axis_size step 1){
                        ret_tensor[((i*axis_size + j*a):(i*axis_size + (j+1)*a):1,)] <- (ttensor[(i:(i+a):1,)])
                        _end_
                    }
                    _end_
                }
                broadcast_shape_f16 input alpha (a) (b*axis_size) ret_tensor (index+1)
            }
        }

    let impl inputnames outputnames inputshapes outputshapes ismutinputs nextop =
        let reshaped_alpha = 
            match alpha with
                | ut.TensorF32 x    -> broadcast_shape_f32 input1_shape alpha_shape alpha_size 1 x 0
                | ut.TensorF16 x    -> broadcast_shape_f16 input1_shape alpha_shape alpha_size 1 x 0
            
        let rec setinputs index nextvar = 
            if(index == (ll.len input_data)){
                nextvar
            } else{
                let data = ll.item index input_data
                let datashape = ll.item index input_shapes
                let folder a b = a * b
                let flattenshape = [ll.fold folder 1 datashape]
                let (layer, edge) = ll.item index input_edges
                let ismaininput = ll.item index input_tomains
                let representative_inputshape = ll.item 0 inputshapes
                let representative_outputshape = ll.item 0 outputshapes
                if((layer == -1) && (ismaininput)){ // set main input
                    let mainedge = ll.item index input_towhichedges
                    let inputname = ll.item mainedge inputnames
                    let inputshape = ll.item mainedge inputshapes
                    let ismut = ll.item mainedge ismutinputs
                    if(ismut){
                        !{
                            let mut ${inputname} = reshapeTo(${ll.toRtTuple inputshape}, &inputs[|${edge}|])
                            ${setinputs (index + 1) nextvar}
                        }
                    } else{
                        !{
                            let ${inputname} = reshapeTo(${ll.toRtTuple inputshape}, inputs[|${edge}|])
                            ${setinputs (index + 1) nextvar}
                        }
                    }
                } else if(!(ut.isEmpty data)){ // alpha
                    let varname = mu.getvarname prefix index 
                    let dataexpr x = 
                        if(ll.len representative_inputshape == 1){
                            !{${x}}
                        } else{
                            let mut inputedge = -1
                            for(i from 0 to (ll.len input_tomains)){
                                if(ll.item i input_tomains){
                                    inputedge <- ll.item i input_towhichedges
                                } else{ 
                                    _end_
                                }
                            }
                            let mut outputedge = -1
                            for(i from 0 to (ll.len output_tomains)){
                                if(ll.item i output_tomains){
                                    outputedge <- ll.item i output_towhichedges
                                } else{ 
                                    _end_
                                }
                            }
                            let varshape = 
                                if(outputedge >= 0){
                                    ll.toRtTuple(ll.item outputedge outputshapes)
                                } else{
                                    ll.toRtTuple(ll.item inputedge inputshapes)
                                }
                            !{reshapeTo(${varshape}, ${x})}
                        }
                    let vardata = 
                        match reshaped_alpha with
                            | ut.TensorI8 x    -> dataexpr x
                            | ut.TensorF16 x   -> dataexpr x
                            | ut.TensorF32 x   -> dataexpr x
                    !{
                        let ${varname} = ${vardata}
                        ${setinputs (index + 1) nextvar}
                    }
                } else if((layer == -1)){ // set micro input
                    let varname = mu.getvarname prefix index
                    let dataexpr x = 
                        if((ll.len representative_inputshape) == 1){ // flatten
                            let varshape = ll.toRtTuple(flattenshape)
                            !{reshapeTo(${varshape}, ${x})}
                        } else{
                            let varshape = ll.toRtTuple(representative_outputshape) // will be problem
                            !{reshapeTo(${varshape}, ${x})}
                        }
                    let vardata = dataexpr (!{&inputs[|${edge}|]})
                    !{
                        let mut ${varname} = ${vardata}
                        ${setinputs (index + 1) nextvar}
                    }
                } else{
                    setinputs (index + 1) nextvar
                }
            }
        let setoutputs nextvar = (
            let (layer, edge) = ll.item 0 output_edges
            let ismainoutput  = ll.item 0 output_tomains
            if((layer == -1) && (ismainoutput)){
                let mainedge = ll.item 0 output_towhichedges
                let outputname = ll.item mainedge outputnames
                let outputshape = ll.item mainedge outputshapes
                !{
                    let mut ${outputname} = reshapeTo(${ll.toRtTuple outputshape}, &outputs[|${edge}|])
                    ${nextvar}
                }
            } else{
                nextvar
            }
        )
        // quantization will be supported
        // let setmultshift nextop =
        setinputs 0 (setoutputs nextop)
    impl


let loopOps layer_param input_shapes input_dtypes input_zero_points output_shapes output_dtypes output_zero_points output_towhichedges prefix =
    // not implemented
    let impl outputnames nextop =
        nextop
    impl

let microOps layer_param input_data input_shapes input_edges output_edges input_tomains output_tomains ismain prefix = 
    // quantization will be supported
    let impl inputvectorname outputvectorname vectorstartidxlist vectorsize vectordtype nextop = 
        let inputvector = inputvectorname
        let outputvector = outputvectorname
        let alphaname = mu.getvarname prefix 1
        let zero = 
            if(vectordtype == rtType(f32)){
                !{0.f32}
            } else if(vectordtype == rtType(f16)){
                !{0.f16}
            } else if(vectordtype == rtType(i8)){
                !{0i8}
            } else if(vectordtype == rtType(i32)){
                !{0i32}
            }
        if(inputvectorname == outputvectorname){
            !{
                ${outputvector} <- __max(${inputvector}, tensor((${vectorsize},), ${zero})) + __min(${inputvector}, tensor((${vectorsize},), ${zero})) * ${alphaname}[${mu.toVectorRangeRtTuple vectorstartidxlist vectorsize}]
                ${nextop}
            }
        } else{
            !{
                let ${outputvector} = __max(${inputvector}, tensor((${vectorsize},), ${zero})) + __min(${inputvector}, tensor((${vectorsize},), ${zero})) * ${alphaname}[${mu.toVectorRangeRtTuple vectorstartidxlist vectorsize}]
                ${nextop}
            }
        }

    impl

let storeOps =  
    // not implemented
    let impl nextop =
        nextop
    impl

let mapIdxCtOps layer_param input_shapes output_shapes =
    let impl idxlist isflatten = 
        idxlist
    impl

let padOps layer_param input_shapes output_shapes = 
    mu.basePadOps layer_param input_shapes output_shapes

let microImpl = (isMain, passScale, setVars, loopOps, microOps, storeOps, padOps)

_end_