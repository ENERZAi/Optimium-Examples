module core.List.List as ll
module common.uniontensor as ut
module common.params as params
module common.layerparams as lparams
module common.utils as commonutils
module micro.utils as mu
// let (isMain, passScale, setVars, loopOps, microOps, storeOps) = getMicroLayerImpl 

let isMain = false

let passScale input_scales output_scales = 
    if(ut.isEmpty input_scale){
        ([1.f], 32, true)
    } else{
        let si = ut.toCtTensorF32 input_scale
        let so = ut.toCtTensorF32 output_scale

        ([si / so], 16, true)
    }

let setVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale = 
    let impl inputnames outputnames inputshapes outputshapes ismutinputs nextop =
        let (inputlayer, inputedge) = ll.item 0 input_edges
        let setinput nextvar =
            if(inputlayer == -1){ // runtime input
                let mainedge = ll.item 0 input_towhichedges
                let inputname = ll.item mainedge inputnames
                let maininputshape = ll.item mainedge inputshapes
                let orginputshape = ll.item 0 input_shapes
                let outputshape = ll.item 0 output_shapes
                let flattenoutputshape = mu.flattenshape outputshape
                let inputshape = 
                    if(ll.len maininputshape == 1){ // flatten
                        if((ll.item 0 maininputshape) >= (ll.item 0 flattenoutputshape)){ // indirect
                            let indirectinputshape = ll.concat ([ll.item 0 orginputshape + 1]) (ll.drop 1 orginputshape)
                            mu.flattenshape indirectinputshape
                        } else{
                            mu.flattenshape orginputshape
                        }
                    } else{
                        orginputshape
                    }
                let ismut = ll.item mainedge ismutinputs
                if(ismut){
                    !{
                        let mut ${inputname} = reshapeTo(${ll.toRtTuple inputshape}, &inputs[|${inputedge}|])
                        ${nextvar}
                    }
                } else{
                    !{
                        let ${inputname} = reshapeTo(${ll.toRtTuple inputshape}, inputs[|${inputedge}|])
                        ${nextvar}
                    }
                }
            } else{
                nextvar
            }
        let (outputlayer, outputedge) = ll.item 0 output_edges
        let setoutput nextvar =
            if(outputlayer == -1){
                let mainoutedge = ll.item 0 output_towhichedges
                let outputname = ll.item mainoutedge outputnames
                let mainoutputshape = ll.item mainoutedge outputshapes
                let padedoutputshape = ll.item 0 output_shapes
                let outputshape = 
                    if((ll.len mainoutputshape) == 1){
                        mu.flattenshape padedoutputshape
                    } else if((ll.len mainoutputshape) == (ll.len padedoutputshape)){
                        padedoutputshape
                    } else{
                        except("pad operation only support flatten or original shape")
                    }
                !{
                    let mut ${outputname} = reshapeTo(${ll.toRtTuple outputshape}, &outputs[|${outputedge}|])
                    ${nextvar}
                }
            } else{
                nextvar
            }
        setinput (setoutput nextop)

    impl

let loopOps layer_param input_shapes input_dtypes input_zero_points output_shapes output_dtypes output_zero_points output_towhichedges prefix =
    let layer_param = 
        match layer_param with
            | params.Pad x  -> x
            | _             -> except("only pad param can be used. check common.params")
    let padding = layer_param->padding
    let input_shape = ll.item 0 input_shapes
    let output_shape = ll.item 0 output_shapes
    let zero_points = ll.item 0 output_zero_points
    let zerotns_str = prefix + "zero_"

    let mainedge = ll.item 0 output_towhichedges
    
    // implementaion reference pad.utils
    let get_pad_chunk_shape replace_index replace_val =
        let rec impl index = 
            if (index  == (ll.len <| input_shape)){
                []
            } else{
                if (index == replace_index){
                    ll.concat <| [replace_val] <| (impl <| (index+1i))
                } else if (index > replace_index){
                    ll.concat <| [ll.item <| index <| output_shape] <| (impl <| (index+1i))
                } else{
                    ll.concat <| [ll.item <| index <| input_shape] <| (impl <| (index+1i))
                }
            }
        impl <| 0i

    let get_pad_chunk_outidx curpadidx paddim_outidx =
        let rec impl index =
            if(index >= (ll.len <| input_shape)){
                []
            } else if(index < curpadidx){
                let pad_front = ll.item <| 0i <| (ll.item <| index <| padding)
                ll.concat <| [pad_front: (pad_front + (ll.item <| index <| input_shape)):1i] <| (impl <| (index+1i))
            } else if(index == curpadidx){
                ll.concat <| [paddim_outidx] <| (impl <| (index+1i))
            } else{
                ll.concat <| [0i : (ll.item <| index <| output_shape):1i] <| (impl <| (index+1i))
            }
        impl <| 0i

    let impl outputnames nextop =
        if(mainedge == -1){
            nextop
        } else{
            let rec setFillPadExpr_impl index =
                if(index >= (ll.len <| input_shape)){
                    !{
                        ${nextop}
                    }
                } else{
                    let outputname = !{${ll.item mainedge outputnames}[|${mainedge}|]}
                    let pad_front = ll.item <| 0i <| (ll.item <| index <| padding)
                    let pad_back    = ll.item <| 1i <| (ll.item <| index <| padding)
                    if( (pad_front + pad_back) == 0i){
                        // nothing to pad
                        setFillPadExpr_impl <| (index + 1i)
                    } else{
                        let front_expr pad_front nextstepop = 
                            if(pad_front > 0){
                                let chunk_shape = get_pad_chunk_shape <| index <| pad_front
                                let flatnum = commonutils.factorial <| chunk_shape
                                match zero_points with
                                | ut.EMPTY -> 
                                    let v = if(ll.item 0 output_dtypes == rtType(f32)){
                                        tensor((flatnum,), 0.0f32)
                                    } else{
                                        tensor((flatnum,), 0.0f16)
                                    }
                                    let outidx = get_pad_chunk_outidx <| index <| (0i:pad_front:1i)
                                    !{
                                        let ${zerotns_str + toStr(index) + "_" + toStr(0)} = ${v}
                                        ${outputname}[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${zerotns_str + toStr(index) + "_" + toStr(0)})
                                        ${nextstepop}
                                    }
                                | ut.TensorI32 tns ->
                                    if(shapeOf(tns)[|0|] == 1i){
                                        // tensor-wise
                                        let v = tensor((flatnum,), tns[(0,)])
                                        let outidx = get_pad_chunk_outidx <| index <| (0i:pad_front:1i)
                                        !{
                                            let ${zerotns_str + toStr(index) + "_" + toStr(0)} = ${v}
                                            ${outputname}[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${zerotns_str + toStr(index) + "_" + toStr(0)})
                                            ${nextstepop}
                                        }
                                    } else{
                                        // channel-wise
                                        except("Not implemented for channel-wise quantization")
                                    }
                                | _ -> except("not supported type for zero points")
                            } else{
                                !{
                                    ${nextstepop}
                                }
                            }
                        let expr1 = front_expr <| pad_front
                        let back_expr pad_back = 
                            if(pad_back > 0){
                                let chunk_shape = get_pad_chunk_shape <| index <| pad_back
                                let flatnum = commonutils.factorial <| chunk_shape
                                match zero_points with
                                | ut.EMPTY ->
                                    let v = if(ll.item 0 output_dtypes == rtType(f32)){
                                        tensor((flatnum,), 0.0f32)
                                    } else{
                                        tensor((flatnum,), 0.0f16)
                                    }
                                    let outidx = get_pad_chunk_outidx <| index <| ((ll.item <| index <| (output_shape)-pad_back):(ll.item <| index <| output_shape):1i)
                                    !{
                                        let ${zerotns_str + toStr(index) + "_" + toStr(1)} = ${v}
                                        ${outputname}[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${zerotns_str + toStr(index) + "_" + toStr(1)})
                                        ${setFillPadExpr_impl <| (index+1i)}
                                    }
                                | ut.TensorI32 tns ->
                                    if(shapeOf(tns)[|0|] == 1i){
                                        // tensor-wise
                                        let v = tensor((flatnum,), tns[(0,)])
                                        let outidx = get_pad_chunk_outidx <| index <| ((ll.item <| index <| (output_shape)-pad_back):(ll.item <| index <| output_shape):1i)
                                        !{
                                            let ${zerotns_str + toStr(index) + "_" + toStr(1)} = ${v}
                                            ${outputname}[${ll.toRtTuple <| outidx}] <- reshapeTo(${ll.toRtTuple <| chunk_shape}, ${zerotns_str + toStr(index) + "_" + toStr(1)})
                                            ${setFillPadExpr_impl <| (index+1i)}
                                        }
                                    } else{
                                        // channel-wise
                                        except("Not implemented for channel-wise quantization")
                                    }
                            } else{
                                !{
                                    ${setFillPadExpr_impl <| (index+1i)}
                                }
                            }
                        let expr2 = back_expr <| pad_back
                        expr1 <| expr2
                    }
                }
            setFillPadExpr_impl <| 0i
        }
    
    impl


let microOps layer_param input_data input_shapes input_edges output_edges input_tomains output_tomains ismain prefix = 
    // quantization will be supported
    let impl inputvectorname outputvectorname vectorstartidxlist vectorsize vectordtype nextop = 
        nextop

    impl

let storeOps =  
    // not implemented
    let impl nextop =
        nextop
    impl

let mapIdxCtOps layer_param input_shapes output_shapes =
    let padding = layer_param->padding
    let input_shape = ll.item 0 input_shapes
    let output_shape = ll.item 0 output_shapes
    let dotprod list1 list2 =
        let prod index =
            let a = ll.item index list1
            let b = ll.item index list2
            a * b
        let rec impl index =
            if(index == ll.len list1 - 1){
                prod index
            } else{
                let out = prod index
                out + (impl (index + 1))
            }
        impl 0
    let getdelta shape =
        let rec impl index = 
            if(index == ll.len shape - 1){
                [1]
            } else{
                let remain = ll.drop (index + 1) shape
                let mul a b = a * b
                let out = ll.fold mul 1 remain
                out; impl (index + 1)
            }
        impl 0
    let idx2offset idx shape = 
        let delta = getdelta shape
        dotprod idx delta
    let offset2idx offset shape =
        let delta = getdelta shape
        let moddiv index =
            let div = ll.item index delta
            let modlist = ll.take index delta
            let mod a b = a % b
            (ll.fold mod offset modlist) / div
        let rec impl index =
            if(index == ll.len shape - 1){
                [moddiv index]
            } else{
                let out = 
                    if(index == 0){
                        let div = ll.item index delta
                        offset / div
                    } else{
                        moddiv index
                    }
                out; impl (index + 1)
            }
        impl 0
    let pad idxlist =
        let impl index =
            if(index == ll.len padding){
                []
            } else{
                let padl = ll.item 0 (ll.item index padding)
                let i = ll.item index idxlist 
                padl + i; impl (index + 1)
            }
        impl 0
    let map idxlist isflatten = 
        if(isflatten){
            let offset = ll.item idxlist
            let idxlist_new = offset2idx offset
            let padded = pad idxlist_new
            [idx2offset padded]
        } else{
            pad idxlist
        }
    map

let padOps layer_param input_shapes output_shapes = 
    let layer_param = 
        match layer_param with
            | params.Pad x  -> x
            | _             -> except("only pad param can be used. check common.params")
    let padding = layer_param->padding
    let input_shape = ll.item 0 input_shapes
    let output_shape = ll.item 0 output_shapes
    let impl preopflag prepadding =
        let paddingop =
            let rec impl index = 
                if(index == ll.len output_shape){
                    []
                } else{
                    let prepadl = ll.item 0 (ll.item index prepadding)
                    let prepadr = ll.item 1 (ll.item index prepadding)
                    let padl = ll.item 0 (ll.item index padding)
                    let padr = ll.item 1 (ll.item index padding)
                    [prepadl + padl; prepadr + padr]; impl (index + 1)
                }
            impl 0
        if(preopflag){
            (paddingop, input_shape)
        } else{
            (paddingop, output_shape)
        }
    impl

let microImpl = (isMain, passScale, setVars, loopOps, microOps, storeOps, padOps)

_end_