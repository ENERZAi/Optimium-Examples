module core.List.List as ll
module common.uniontensor as ut
module micro.utils as mu
// let (isMain, passScale, setVars, loopOps, microOps, storeOps) = getMicroLayerImpl 

let isMain = false

let passScale input_scales output_scales = 
    let input_scale = ll.item 0 input_scales
    let output_scale = ll.item 0 output_scales

    if(ut.isEmpty input_scale){
        ([1.f], 32, true)
    } else{
        let si = ut.toCtTensorF32 input_scale
        let so = ut.toCtTensorF32 output_scale

        ([si / so], 16, true)
    }

let setVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale = 
    mu.baseNotMainSetVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale

let loopOps layer_param input_shapes input_dtypes input_zero_points output_shapes output_dtypes output_zero_points output_towhichedges prefix =
    // not implemented
    let impl outputnames nextop =
        nextop
    impl

let microOps layer_param input_data input_shapes input_edges output_edges input_tomains output_tomains ismain prefix = 
    // quantization will be supported
    let impl inputvectorname outputvectorname vectorstartidxlist vectorsize vectordtype nextop = 
        let inputvector = inputvectorname
        let outputvector = outputvectorname
        let (zero, six) = 
            if(vectordtype == rtType(f32)){
                (!{0.f32}, !{6.f32})
            } else if(vectordtype == rtType(f16)){
                (!{0.f16}, !{6.f16})
            } else if(vectordtype == rtType(i8)){
                (!{0i8}, !{6i8})
            } else if(vectordtype == rtType(i32)){
                (!{0i32}, !{6i32})
            }
        if(inputvectorname == outputvectorname){
            !{
                ${outputvector} <- __min(__max(${inputvector}, tensor((${vectorsize},), ${zero})), tensor((${vectorsize},), ${six}))
                ${nextop}
            }
        } else{
            !{
                let ${outputvector} = __min(__max(${inputvector}, tensor((${vectorsize},), ${zero})), tensor((${vectorsize},), ${six}))
                ${nextop}
            }
        }

    impl

let storeOps =  
    // not implemented
    let impl nextop =
        nextop
    impl

let mapIdxCtOps layer_param input_shapes output_shapes =
    let impl idxlist isflatten = 
        idxlist
    impl

let padOps layer_param input_shapes output_shapes = 
    mu.basePadOps layer_param input_shapes output_shapes

let microImpl = (isMain, passScale, setVars, loopOps, microOps, storeOps, padOps)

_end_