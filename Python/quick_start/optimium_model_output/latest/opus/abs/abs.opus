module core.List.List as ll
module common.uniontensor as ut
module common.params as params

template</attr_params: params.Attributes, optim_params: params.Optimization, layer_params: ll.List<params.Layerargs>,
    input_data: ll.List<ll.List<ut.UnionTensor>>, input_dtypes: ll.List<ll.List<rtType>>, input_shapes: ll.List<ll.List<i32>>, input_scales: ll.List<ll.List<ut.UnionTensor>>, input_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    output_dtypes: ll.List<ll.List<rtType>>, output_shapes: ll.List<ll.List<i32>>, output_scales: ll.List<ll.List<ut.UnionTensor>>, output_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    input_edges: ll.List<ll.List<tuple<i32, i32>>>, output_edges: ll.List<ll.List<tuple<i32, i32>>>, ismainops: ll.List<boolean>,
    input_t: rtType, input_rt_list : ll.List<rtType>,  output_t: rtType, output_rt_list : ll.List<rtType>/>
attr[Extern : attr_params->name, Optimization : { VectorSize : 512 }]
fun abs(inputs: input_t, mut &outputs: output_t) -> i32 {
    ${
        let layerindex = (
            let mut index = 0
            for(i from 0 to (ll.len layer_params)){
                match (ll.item i layer_params) with 
                    | params.Abs x   -> if((ll.item i ismainops)){index <- i} else{_end_}
                    | _                 -> _end_
            }
            index
        )
        let thislayer_params = 
            match (ll.item index layer_params) with
                | params.Abs x -> x
        
        let input_dtype = ll.item 0 (ll.item layerindex input_dtypes)
        let input_shape = ll.item 0 (ll.item layerindex input_shapes)
        let input_scales = ll.item 0 (ll.item layerindex input_scales)
        let input_zero_points = ll.item 0 (ll.item layerindex input_zero_points)
        let output_dtype = ll.item 0 (ll.item layerindex output_dtypes)
        let output_shape = ll.item 0 (ll.item layerindex output_shapes)
        let output_scales = ll.item 0 (ll.item layerindex output_scales)
        let output_zero_points = ll.item 0 (ll.item layerindex output_zero_points)
        let pack = ll.item 0 (optim_params->pack)
        let unroll = ll.item 0 (optim_params->unroll)
        
        for (i from 0 to (ll.len output_shape)){
            if(ll.item i output_shape == ll.item i input_shape){
                _end_
            } else{
                except("output shape(" + toStr(output_shape) + ") is not compatible with expected shape(" + toStr(input_shape) + "}")
            }
        }
        let zero_tensor = if (input_dtype== rtType(f32)){
                ut.TensorF32(tensor((1,), 0.f32))
            }else if(input_dtype == rtType(f16)){
                ut.TensorF16(tensor((1,), 0.f16))
            }else if(input_dtype == rtType(i8)){
                input_zero_points
            } else{
                except("type error")
            }


        let rec shape_size index shape data =
            if(index == ll.len shape){
                data
                
            } else{
                shape_size (index+1) shape (data*(ll.item index shape))
            }
        let input_size = shape_size 0 input_shape 1
        let output_size = shape_size 0 output_shape 1
        let _ = if(pack * unroll > input_size){
            except("pack * unroll(" + toStr(pack * unroll) + ") should be larger than one of the shape of last dimension of input(" + toStr(input_size) + ")")
        } else{
            _end_
        }
        let tiles =
            if(input_size % (pack*unroll) == 0){
                [(0, input_size); (input_size, input_size)]
            } else{
                let end1 = input_size - (input_size % (pack*unroll))
                [(0, end1); (end1, input_size)]
            }

        let isQuant = if(input_dtype == rtType(i8)){true} else{false}
        let isF16 = if(input_dtype == rtType(f16)){true} else{false}

        let (start1, end1) = ll.item 0 tiles
        let (start2, end2) = ll.item 1 tiles

        let rec expr step_size num = 
            if(num < unroll){
                if(isQuant){
                !{  
                    cal_tensor <- cast<i32>((flat_input[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)]) - ${ut.toRtTensor zero_tensor})
                    cal_tensor <- (mul * cal_tensor) >> tensor((1,), 8i)
                    cal_tensor <- __max(cal_tensor,-cal_tensor)+ ${ut.toRtTensor output_zero_points}
                    cal_tensor <- __min(__max(cal_tensor,tensor((1,), -128i)),tensor((1,), 127i))
                    flat_output[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)]  <- cast<i8>(cal_tensor)
                    ${expr step_size (num+1)}                    
                }
            }else if(isF16){
                !{
                    flat_output[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)] <- __max(flat_input[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)],-flat_input[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)])
                    ${expr step_size (num+1)}
                }
                
            }else{

                !{  
                    flat_output[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)] <- __max(flat_input[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)],-flat_input[(idx+${step_size*num}:(idx + ${step_size*(num+1)}):1i,)])
                    ${expr step_size (num+1)}
                }
            }
            }else{
                !{_end_}
            }
             
        let chk_element = 
            if(end2 - start2 > 0){
                if(isQuant){
                    !{  
                        for(idx from ${start1} to ${end1} step ${pack*unroll}){
                            ${expr pack 0}
                        }
                        let cal_input = cast<i16>((flat_input[(${start2}:${end2}:1i,)] ) - ${ut.toRtTensor zero_tensor})
                        let abs_data = __max(cal_input,-cal_input)
                        let no_cast = ((mul * abs_data) >> tensor((1,), 8i)) + ${ut.toRtTensor output_zero_points}
                        let clip_data = __min(__max(no_cast,tensor((1,), -128i)),tensor((1,), 127i))
                        flat_output[(${start2}:${end2}:1i,)] <- cast<i8>(clip_data)
                        0
                    }
                }else if(isF16){
                    
                    !{  
                        for(idx from ${start1} to ${end1} step ${pack*unroll}){
                            ${expr pack 0}
                        }
                        flat_output[(${start2}:${end2}:1i,)]  <- __max(flat_input[(${start2}:${end2}:1i,)] ,-flat_input[(${start2}:${end2}:1i,)])
                        0
                    }
                }else{
                    !{  
                        for(idx from ${start1} to ${end1} step ${pack*unroll}){
                            ${expr pack 0}
                        }
                        flat_output[(${start2}:${end2}:1i,)]  <- __max(flat_input[(${start2}:${end2}:1i,)] ,-flat_input[(${start2}:${end2}:1i,)])
                        0
                        
                    }
                }
            }else{
                !{  
                    for(idx from ${start1} to ${end1} step ${pack*unroll}){
                        ${expr pack 0}
                    }
                    0
                }
            } 
            
        if(isQuant){
            let mul = cast<i32>((ut.toCtTensorF32 input_scales/(ut.toCtTensorF32 output_scales)) * (tensor((1,), 256.f)) + (tensor((1,), 0.5f)))
            !{  
                let mut batchoutput = &outputs[|0|]
                let batchinput = inputs[|0|]
                let mul = ${mul}
                let flat_input = reshapeTo(${(input_size,)}, batchinput)
                let mut flat_output = reshapeTo((${output_size},),&batchoutput)
                let mut cal_tensor = tensor((${pack},), 0i8)
                ${chk_element}
            }
        }else if(isF16){
                !{  
                    
                let mut batchoutput = &outputs[|0|]
                let batchinput = inputs[|0|]
                let flat_input = reshapeTo(${(input_size,)}, batchinput)
                let mut flat_output = reshapeTo((${output_size},),&batchoutput)
                ${chk_element}
                }
        } else{
            !{
                let mut batchoutput = &outputs[|0|]
                let batchinput = inputs[|0|]
                let flat_input = reshapeTo(${(input_size,)}, batchinput)
                let mut flat_output = reshapeTo((${output_size},),&batchoutput)
                ${chk_element}
            }
        }
    }

     
}

