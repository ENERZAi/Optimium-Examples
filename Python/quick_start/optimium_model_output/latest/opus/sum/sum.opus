module core.List.List as ll
module reduce.utils as u
module common.utils as commonutils
module common.uniontensor as ut
module common.params as params
module reduce.expr as exprutils

template</attr_params: params.Attributes, optim_params: params.Optimization, layer_params: ll.List<params.Layerargs>,
    input_data: ll.List<ll.List<ut.UnionTensor>>, input_dtypes: ll.List<ll.List<rtType>>, input_shapes: ll.List<ll.List<i32>>, input_scales: ll.List<ll.List<ut.UnionTensor>>, input_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    output_dtypes: ll.List<ll.List<rtType>>, output_shapes: ll.List<ll.List<i32>>, output_scales: ll.List<ll.List<ut.UnionTensor>>, output_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    input_edges: ll.List<ll.List<tuple<i32, i32>>>, output_edges: ll.List<ll.List<tuple<i32, i32>>>, ismainops: ll.List<boolean>,
    input_t: rtType, input_rt_list : ll.List<rtType>,  output_t: rtType, output_rt_list : ll.List<rtType>/>
attr[Extern : attr_params->name, Optimization : { VectorSize : 512 }]
fun sum(input: input_t, mut &output: output_t) -> i32 {
    ${
        let pack = ll.item 0 (optim_params->pack)
        let input_dtype = ll.item 0 (ll.item 0 input_dtypes)
        let input_shape = ll.item 0 (ll.item 0 input_shapes)
        let input_scale = ll.item 0 (ll.item 0 input_scales)
        let input_zero_point = ll.item 0 (ll.item 0 input_zero_points)
        let output_shape = ll.item 0 (ll.item 0 output_shapes)
        let output_scale = ll.item 0 (ll.item 0 output_scales)
        let output_zero_point = ll.item 0 (ll.item 0 output_zero_points)

        let thislayer_params = 
            match (ll.item 0 layer_params) with 
                | params.Sum x -> x

        let axis = thislayer_params->dim
        let keepdim = thislayer_params->keepdim


        let templateparams = u.TemplateParameters(input_t, input_dtypes, input_shapes, input_scales, input_zero_points,
                                            output_t, output_dtypes, output_shapes, output_scales, output_zero_points,
                                            pack, axis, keepdim, )
        let params = u.initCodeGen templateparams

        // ASSUME tensor-wise scheme for quantization
        let in_zero_val =
            if (params->is_quant) {
                u.index_uniontensor <| (0,) <| input_zero_point
            } else {
                0i32
            }
        
        if (params->last_consec_parallel_axis >= 0) {
            let output_packed_shape = ll.concat <| params->outer_indices <| [params->last_parallel_size;]
            let input_packed_shape = 
                ll.concat <| (u.get_list_slice <| 0 <| params->last_consec_parallel_axis <| input_shape) <| [params->last_parallel_size;]

            let ct_input_zero = 
                if (params->is_quant) {
                    ut.TensorI32(tensor((pack,), cast<i32>(in_zero_val)))
                } else {
                    ut.TensorF32(tensor((pack,), 0.f32))
                }


            let innermost_sum_expr last_parallel_access = 
                if (params->is_quant) {
                    !{
                        // TODO
                        let input_vec = (cast<i32>(${params->reshaped_input_name}[${(ll.toRtTuple <| (ll.concat <| params->input_iters <| last_parallel_access))}]) - ${ut.toRtTensor <| ct_input_zero})
                        ${params->reduction_vecname} <- ${params->reduction_vecname} + input_vec
                    }
                } else {
                    !{
                        ${params->reduction_vecname} <- ${params->reduction_vecname} + ${params->reshaped_input_name}[${(ll.toRtTuple <| (ll.concat <| params->input_iters <| last_parallel_access) )}]
                    }
                }

            !{
                let mut ${params->batch_output_name} = &output[|0|]
                let ${params->batch_input_name} = input[|0|]
                let ${params->reshaped_input_name} = reshapeTo(${ll.toRtTuple <| input_packed_shape}, batchinput)
                let mut ${params->reshaped_output_name} = reshapeTo(${ll.toRtTuple <| output_packed_shape}, batchoutput)
                ${
                    exprutils.get_reduction_op_for_loop <| params <| innermost_sum_expr
                }
            }
        } else {
            let innermost_sum_expr last_parallel_access = 
                if (params->is_quant){
                    !{
                        let input_val = cast<i32>(${params->batch_input_name}[${(ll.toRtTuple <| (ll.concat <| params->input_iters <| last_parallel_access))}]) - ${in_zero_val}
                        ${params->reduction_vecname} <- ${params->reduction_vecname} + input_val
                    }
                } else {
                    !{
                        ${params->reduction_vecname} <- ${params->reduction_vecname} + ${params->batch_input_name}[${(ll.toRtTuple <| (ll.concat <| params->input_iters <| last_parallel_access))}]
                    }
                }

            !{
                let mut ${params->batch_output_name} = &output[|0|]
                let ${params->batch_input_name} = input[|0|]
                let mut ${params->reshaped_output_name} = &${params->batch_output_name}
                ${
                    exprutils.get_reduction_op_for_loop <| params <| innermost_sum_expr
                }
            }
        }
    }
}