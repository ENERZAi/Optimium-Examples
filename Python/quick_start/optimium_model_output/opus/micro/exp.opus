module core.List.List as ll
module common.uniontensor as ut
module micro.utils as mu
// let (isMain, passScale, setVars, loopOps, microOps, storeOps) = getMicroLayerImpl

let isMain = false

let passScale input_scales output_scales =
    let input_scale = ll.item 0 input_scales
    let output_scale = ll.item 0 output_scales

    if(ut.isEmpty input_scale){
        ([1.f], 32, true)
    } else{
        let si = ut.toCtTensorF32 input_scale
        let so = ut.toCtTensorF32 output_scale

        ([si / so], 16, true)
    }

let setVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale = 
    mu.baseNotMainSetVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale

let loopOps layer_param input_shapes input_dtypes input_zero_points output_shapes output_dtypes output_zero_points output_towhichedges prefix =
    // not implemented
    let impl outputnames nextop =
        nextop
    impl

let microOps layer_param input_data input_shapes input_edges output_edges input_tomains output_tomains ismain prefix = 
    // quantization will be supported
    let impl inputvectorname outputvectorname vectorstartidxlist vectorsize vectordtype nextop =
        let inputvector = inputvectorname
        let outputvector = outputvectorname
        let zero =
            if(vectordtype == rtType(f32)){
                !{0.f32}
            } else if(vectordtype == rtType(f16)){
                !{0.f16}
            } else if(vectordtype == rtType(i8)){
                !{0i8}
            } else if(vectordtype == rtType(i32)){
                !{0i32}
            }

        let get_constants size =
            if (vectordtype == rtType(f32)) {
                !{
                    let magic_bias = tensor((${size},), 12583039.000000f) // 2 ^ 24 - 2 ^ 22 + 127
                    let log2e = tensor((${size},), 1.4426950216293335f)
                    let minus_ln2 = tensor((${size},), -0.6931471824645996f)
                    let denorm_cutoff = tensor((${size},), -87.33654022216797f) // f32

                    let c1 = tensor((${size},), 0.9999997019767761f)
                    let c2 = tensor((${size},), 0.4999915063381195f)
                    let c3 = tensor((${size},), 0.1666765213012695f)
                    let c4 = tensor((${size},), 0.0418978221714497f)
                    let c5 = tensor((${size},), 0.0082892905920744f)

                    let one = tensor((${size},), 1.0f)
                    let zeros = tensor((${size},), 0.0f)
                    let shifts = tensor((${size},), 23i)

                    (&magic_bias, &log2e, &minus_ln2, &denorm_cutoff, &c1, &c2, &c3, &c4, &c5, &one, &zeros, &shifts)
                }
            } else if (vectordtype == rtType(f16)) {
                !{
                    let magic_bias = tensor((${size},), 12583039.000000f) // 2 ^ 24 - 2 ^ 22 + 127
                    let log2e = tensor((${size},), 1.4426950216293335f)
                    let minus_ln2 = tensor((${size},), -0.6931471824645996f)
                    let denorm_cutoff = tensor((${size},), -9.703125f)

                    let c1 = tensor((${size},), 0.9999668598175048828125f)
                    let c2 = tensor((${size},), 0.50003015995025634765625f)
                    let c3 = tensor((${size},), 0.16787450015544891357421875f)
                    let c4 = tensor((${size},), 0.0415136031806468963623046875f)

                    let one = tensor((${size},), 1.0f)
                    let zeros = tensor((${size},), 0.0f)
                    let shifts = tensor((${size},), 23i)

                    (&magic_bias, &log2e, &minus_ln2, &denorm_cutoff, &c1, &c2, &c3, &c4, &one, &zeros, &shifts)
                }
            } else {
                except("unsupported type: only f32, f16 supported")
            }

        let calculate_exp =
            if (vectordtype == rtType(f32)) {
                !{
                    let x = ${inputvector}
                    let mut n = x * log2e + magic_bias
                    let bitcasted = bitcast<i32>(n)

                    let s = bitcast<f32>(bitcasted << shifts)

                    n <- -(magic_bias - n)

                    let mut t = n * minus_ln2 + x

                    let mut p = c5 * t + c4 // 5th order approximation
                    p <- p * t + c3
                    p <- p * t + c2
                    p <- p * t + c1

                    t <- t * s
                    let f1 = t * p + s

                    let is_cutoff = cast<f32>(cast<i32>(x < denorm_cutoff))
                    let f2 = is_cutoff * zeros + (one - is_cutoff) * f1
                    &f2
                }
            } else if (vectordtype == rtType(f16)) {
                !{
                    let x = cast<f32>(${inputvector})
                    let mut n = x * log2e + magic_bias
                    let bitcasted = bitcast<i32>(n)

                    let s = bitcast<f32>(bitcasted << shifts)

                    n <- -(magic_bias - n)

                    let mut t = n * minus_ln2 + x

                    let mut p = c4 * t + c3 // 5th order approximation
                    p <- p * t + c2
                    p <- p * t + c1

                    t <- t * s
                    let f1 = t * p + s

                    let is_cutoff = cast<f32>(cast<i32>(x < denorm_cutoff))
                    let f2 = is_cutoff * zeros + (one - is_cutoff) * f1
                    &f2
                }
            } else {
                except("unsupported type: only f32, f16 supported")
            }

        let last_expr =
            if (inputvectorname == outputvectorname) {
                !{
                    ${outputvector} <- result
                    ${nextop}
                }
            } else {
                !{
                    let ${outputvector} = result
                    ${nextop}
                }
            }

        if (vectordtype == rtType(f32)) {
            !{
                let (magic_bias, log2e, minus_ln2, denorm_cutoff, c1, c2, c3, c4, c5, one, zeros, shifts) = ${get_constants vectorsize}
                let result = ${calculate_exp}

                ${last_expr}
            }
        } else {
            !{
                let (magic_bias, log2e, minus_ln2, denorm_cutoff, c1, c2, c3, c4, one, zeros, shifts) = ${get_constants vectorsize}
                let result = cast<f16>(${calculate_exp})

                ${last_expr}
            }
        }

    impl

let storeOps =
    // not implemented
    let impl nextop =
        nextop
    impl

let mapIdxCtOps layer_param input_shapes output_shapes =
    let impl idxlist isflatten =
        idxlist
    impl

let padOps layer_param input_shapes output_shapes =
    mu.basePadOps layer_param input_shapes output_shapes

let microImpl = (isMain, passScale, setVars, loopOps, microOps, storeOps, padOps)

_end_
