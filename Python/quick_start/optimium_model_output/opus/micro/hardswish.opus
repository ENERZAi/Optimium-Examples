module core.List.List as ll
module common.uniontensor as ut
module micro.utils as mu
// let (isMain, passScale, setVars, loopOps, microOps, storeOps) = getMicroLayerImpl 

let isMain = false

let passScale input_scales output_scales = 
    let input_scale = ll.item 0 input_scales
    let output_scale = ll.item 0 output_scales

    if(ut.isEmpty input_scale){
        ([1.f], 32, true)
    } else{
        let si = ut.toCtTensorF32 input_scale
        let so = ut.toCtTensorF32 output_scale

        ([si / so], 16, true)
    }

let setVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale = 
    mu.baseNotMainSetVars layer_param input_data input_shapes input_zero_points output_shapes output_zero_points input_edges output_edges input_tomains output_tomains input_towhichedges output_towhichedges ismain prefix accumscale

let loopOps layer_param input_shapes input_dtypes input_zero_points output_shapes output_dtypes output_zero_points output_towhichedges prefix =
    // not implemented
    let impl outputnames nextop =
        nextop
    impl

let microOps layer_param input_data input_shapes input_edges output_edges input_tomains output_tomains ismain prefix = 
    // quantization will be supported
    let impl inputvectorname outputvectorname vectorstartidxlist vectorsize vectordtype nextop = 
        let inputvector = inputvectorname
        let outputvector = outputvectorname
        let zero = 
            if(vectordtype == rtType(f32)){
                !{0.f32}
            } else if(vectordtype == rtType(f16)){
                !{0.f16}
            } else if(vectordtype == rtType(i8)){
                !{0i8}
            } else if(vectordtype == rtType(i32)){
                !{0i32}
            }
        let one = 
            if(vectordtype == rtType(f32)){
                !{1.f32}
            } else if(vectordtype == rtType(f16)){
                !{1.f16}
            } else if(vectordtype == rtType(i8)){
                !{1i8}
            } else if(vectordtype == rtType(i32)){
                !{1i32}
            }
        let sixth = 
            if(vectordtype == rtType(f32)){
                !{1.f32/6.f32}
            } else if(vectordtype == rtType(f16)){
                !{1.f16/6.f16}
            } else if(vectordtype == rtType(i8)){
                !{1i8}
            } else if(vectordtype == rtType(i32)){
                !{1i32}
            }
        let half = 
            if(vectordtype == rtType(f32)){
                !{0.5f32}
            } else if(vectordtype == rtType(f16)){
                !{0.5f16}
            } else if(vectordtype == rtType(i8)){
                !{1i8}
            } else if(vectordtype == rtType(i32)){
                !{1i32}
            }
        if(inputvectorname == outputvectorname){
            !{
                ${outputvector} <- (
                    let x = ${inputvector}
                    let mut acc = x * tensor((${vectorsize},), ${sixth}) + tensor((${vectorsize},), ${half})
                    acc <- __max(acc, tensor((${vectorsize},), ${zero}))
                    acc <- __min(acc, tensor((${vectorsize},), ${one}))
                    acc * x
                )
                ${nextop}
            }
        } else{
            !{
                let ${outputvector} = (
                    let x = ${inputvector}
                    let mut acc = x * tensor((${vectorsize},), ${sixth}) + tensor((${vectorsize},), ${half})
                    acc <- __max(acc, tensor((${vectorsize},), ${zero}))
                    acc <- __min(acc, tensor((${vectorsize},), ${one}))
                    acc * x
                )
                ${nextop}
            }
        }

    impl

let storeOps =  
    // not implemented
    let impl nextop =
        nextop
    impl

let mapIdxCtOps layer_param input_shapes output_shapes =
    let impl idxlist isflatten = 
        idxlist
    impl

let padOps layer_param input_shapes output_shapes = 
    mu.basePadOps layer_param input_shapes output_shapes

let microImpl = (isMain, passScale, setVars, loopOps, microOps, storeOps, padOps)

_end_