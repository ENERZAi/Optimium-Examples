module core.List.List as ll
module common.utils as commonutils
module common.layerparams as lparams
module common.params as params

template</attr_params: params.Attributes, optim_params: params.Optimization, layer_params: ll.List<params.Layerargs>,
    input_data: ll.List<ll.List<ut.UnionTensor>>, input_dtypes: ll.List<ll.List<rtType>>, input_shapes: ll.List<ll.List<i32>>, input_scales: ll.List<ll.List<ut.UnionTensor>>, input_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    output_dtypes: ll.List<ll.List<rtType>>, output_shapes: ll.List<ll.List<i32>>, output_scales: ll.List<ll.List<ut.UnionTensor>>, output_zero_points: ll.List<ll.List<ut.UnionTensor>>,
    input_edges: ll.List<ll.List<tuple<i32, i32>>>, output_edges: ll.List<ll.List<tuple<i32, i32>>>, ismainops: ll.List<boolean>,
    input_t: rtType, input_rt_list : ll.List<rtType>,  output_t: rtType, output_rt_list : ll.List<rtType>/>
attr[Extern : attr_params->name, Optimization : { VectorSize : 512 }]
fun castnadya(inputs : input_t, mut &outputs: output_t) -> i32{
    ${
        let layerindex = (
            let mut index = 0
            for(i from 0 to (ll.len layer_params)){
                match (ll.item i layer_params) with 
                    | params.Castnadya x   -> if((ll.item i ismainops)){index <- i} else{_end_}
                    | _                 -> _end_
            }
            index
        )

        let layerparams = 
            match (ll.item layerindex layer_params) with 
                | params.Castnadya x -> x
        
        let casttype = layerparams->dtype

        let pack = ll.item 0 (optim_params->pack)
        let unroll = ll.item 0 (optim_params->unroll)
        let input1_dtype = ll.item 0 (ll.item layerindex input_dtypes)
        let input1_shape = ll.item 0 (ll.item layerindex input_shapes)
        let input1_scale = ll.item 0 (ll.item layerindex input_scales)
        let input1_zero_point = ll.item 0 (ll.item layerindex input_zero_points)
        let output_dtype = ll.item 0 (ll.item layerindex output_dtypes)
        let output_shape = ll.item 0 (ll.item layerindex output_shapes)
        let output_scale = ll.item 0 (ll.item layerindex output_scales)
        let output_zero_point = ll.item 0 (ll.item layerindex output_zero_points)

        let castrt = 
            if (casttype == "FLOAT32"){
                rtType(f32)
            } else if (casttype == "FLOAT16"){
                rtType(f16)
            } else if (casttype == "FLOAT64"){
                rtType(f64)
            } else{
                except("For now, only float casting is supported")
            }

        for (i from 0 to (ll.len output_shape)){
            if(ll.item i output_shape == ll.item i input1_shape){
                _end_
            } else{
                except("output shape(" + toStr(output_shape) + ") is not compatible with expected shape(" + toStr(input1_shape) + "}")
            }
        }

        let rec shape_size index shape data =
            if(index == (ll.len shape)){
                data
            }
            else{
                shape_size (index+1) shape (data*(ll.item index shape))
            }
        let input1_size = shape_size 0 input1_shape 1
        let output_size = shape_size 0 output_shape 1

        let _ = if((pack * unroll > input1_size)){
            except("pack * unroll(" + toStr(pack * unroll) + ") should be larger than size of input1(" + toStr(input1_size) + ")")
        } else{
            _end_
        }
        
        let tiles =
            if(input1_size % (pack*unroll) == 0){
                [(0, input1_size); (input1_size, input1_size)]
            } else{
                let end1 = input1_size - (input1_size % (pack*unroll))
                [(0, end1); (end1, input1_size)]
            }
        
        let (start, end) = ll.item 0 tiles
        let (start2, end2) = ll.item 1 tiles
        
        let rec tem num = 
            if (num == unroll + 1){
                !{
                    _end_
                }
            } else{
                !{
                    outp[(idx0+${(num-1)*pack}:idx0+${num*(pack)}:1i,)] <- cast</castrt/>(batchin[(idx0+${(num-1)*pack}:idx0+${num*(pack)}:1i,)])
                    ${tem (num+1)}
                }
            }
        let rec tem2 num last = 
            if(last - num == 0){
                !{
                    //batchoutput <- reshapeTo(${ll.toRtTuple output_shape},outp)
                    0
                }
            } else if (last - num < pack){
                !{
                    outp[(${num}:${last}:1i,)] <- cast</castrt/>(batchin[(${num}:${last}:1i,)])
                    //batchoutput <- reshapeTo(${ll.toRtTuple output_shape},outp)
                    0
                }
            } else{
                !{
                    outp[(${num}:${num + pack}:1i,)] <- cast</castrt/>(batchin[(${num}:${num + pack}:1i,)])
                    ${tem2 (num+pack) last}
                }
            }
        
        !{
            let mut batchoutput = &outputs[|0|]
            let batchinput1 = inputs[|0|]
            let batchin = reshapeTo((${input1_size},),batchinput1)
            let mut outp = reshapeTo((${output_size},),&batchoutput)
            let mut flag = tensor((${pack},),0f16)
            for(idx0 from 0 to ${start2} step ${pack*unroll}){
                ${tem 1}
            }
            ${tem2 start2 end2}
        }
        // !{
        //     let batchinput = inputs[|0|]
        //     let mut batchoutput = &outputs[|0|]
        //     batchoutput <- cast</castrt/>(batchinput)
        //     0.f32
        // }
    }
    
}